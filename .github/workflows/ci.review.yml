name: AI Code Review with Hugging Face

on:
  pull_request:
    types: [opened, synchronize, reopened]

permissions:
  pull-requests: write

jobs:
  code-review:
    runs-on: ubuntu-latest
    steps:
      # 1. Checkout the code
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 

      # 2. Install necessary dependencies
      - name: Install dependencies
        run: |
          sudo apt update
          sudo apt install -y git cmake make g++ unzip wget curl

      # 3. Setup Hugging Face API Token (stored in GitHub secrets)
      - name: Setup Hugging Face Token
        run: |
          echo "HUGGINGFACE_TOKEN=${{ secrets.HUGGINGFACE_TOKEN }}" >> $GITHUB_ENV

      # 4. Clone llama.cpp repository
      - name: Clone llama.cpp repository
        run: git clone https://github.com/ggerganov/llama.cpp.git

      # 5. Build llama.cpp using CMake
      - name: Build llama.cpp using CMake
        run: |
          cd llama.cpp
          mkdir -p build && cd build
          cmake -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=bin ..
          cmake --build . --parallel

      - name: Check built executables
        run: ls -l llama.cpp/build/bin

      - name: Find executable file
        run: |
          EXECUTABLE=$(find llama.cpp/build/bin -type f -executable | head -n 1)
          if [ -z "$EXECUTABLE" ]; then
            echo "No executable found!"
            exit 1
          fi
          echo "EXECUTABLE=$EXECUTABLE" >> $GITHUB_ENV
          echo "Found executable: $EXECUTABLE"

      - name: Download model from Hugging Face
        run: |
          mkdir -p models
          curl -L -H "Authorization: Bearer $HUGGINGFACE_TOKEN" \
            -o models/tinyllama.gguf \
            https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q2_K.gguf

      # 7. Fetch the code diff from the pull request using files instead of diff
      - name: Fetch changed files
        run: |
          git fetch origin ${{ github.event.pull_request.base.ref }} --depth=1
          FILES=$(git diff --name-only origin/${{ github.event.pull_request.base.ref }})

          if [ -z "$FILES" ]; then
            echo "No files changed in this PR."
            exit 1
          fi

          echo "FILES=$FILES" >> $GITHUB_ENV
          echo "Fetched files: $FILES"

      # 8. Run AI Code Review
      - name: Run AI Code Review
        run: |
          chmod +x llama.cpp/build/bin/llama-save-load-state
          DIFF_TEXT="Reviewing the following files: $FILES"
          EXECUTABLE=$(realpath llama.cpp/build/bin/llama-save-load-state)
          $EXECUTABLE -m $(realpath models/tinyllama.gguf) -p "$DIFF_TEXT" > ../../review.txt

      # 9. Post AI review as a comment to the pull request
      - name: Post AI Review as Comment
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # GitHub Action에서 기본 제공하는 토큰
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # GitHub CLI에 사용할 토큰
        run: |
          # review.txt의 절대경로를 OUTPUT_FILE에 저장
          OUTPUT_FILE=$(realpath ../../review.txt)
          
          # 절대경로로 review.txt 파일 읽기
          COMMENT=$(cat "$OUTPUT_FILE")
          
          # Pull request에 댓글 달기
          gh pr comment ${{ github.event.pull_request.number }} --body "$COMMENT"

