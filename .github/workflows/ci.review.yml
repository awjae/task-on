name: AI Code Review with Hugging Face

on:
  pull_request:
    types: [opened, synchronize, reopened]

permissions:
  pull-requests: write

jobs:
  code-review:
    runs-on: ubuntu-latest
    steps:
      # 1. Checkout the code
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 

      # 2. Install necessary dependencies
      - name: Install dependencies
        run: |
          sudo apt update
          sudo apt install -y git cmake make g++ unzip wget curl

      # 3. Setup Hugging Face API Token (stored in GitHub secrets)
      - name: Setup Hugging Face Token
        run: |
          echo "HUGGINGFACE_TOKEN=${{ secrets.HUGGINGFACE_TOKEN }}" >> $GITHUB_ENV

      # 4. Clone llama.cpp repository
      - name: Clone llama.cpp repository
        run: git clone https://github.com/ggerganov/llama.cpp.git

      # 5. Build llama.cpp using CMake
      - name: Build llama.cpp using CMake
        run: |
          cd llama.cpp
          mkdir -p build && cd build
          cmake -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=bin ..
          cmake --build . --parallel

      - name: Check built executables
        run: ls -l llama.cpp/build/bin

      - name: Find executable file
        run: |
          EXECUTABLE=$(find llama.cpp/build/bin -type f -executable | head -n 1)
          if [ -z "$EXECUTABLE" ]; then
            echo "No executable found!"
            exit 1
          fi
          echo "EXECUTABLE=$EXECUTABLE" >> $GITHUB_ENV
          echo "Found executable: $EXECUTABLE"

      - name: Download model from Hugging Face
        run: |
          mkdir -p models
          curl -L -H "Authorization: Bearer $HUGGINGFACE_TOKEN" \
            -o models/tinyllama.gguf \
            https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-GGUF/resolve/main/tinyllama.gguf

      # 7. Fetch the code diff from the pull request using files instead of diff
      - name: Fetch changed files
        run: |
          git fetch origin ${{ github.event.pull_request.base.ref }} --depth=1
          FILES=$(git diff --name-only origin/${{ github.event.pull_request.base.ref }})

          if [ -z "$FILES" ]; then
            echo "No files changed in this PR."
            exit 1
          fi

          echo "FILES=$FILES" >> $GITHUB_ENV
          echo "Fetched files: $FILES"

      - name: Debug built files
        run: |
          echo "Current working directory:"
          pwd
          echo "Checking files in build/bin/"
          ls -l llama.cpp/build/bin/

      - name: Ensure executable permissions
        run: chmod +x $EXECUTABLE

      - name: Debug executable path
        run: |
          echo "EXECUTABLE: $EXECUTABLE"
          file $EXECUTABLE

      # 8. Run AI Code Review
      - name: Run AI Code Review
        run: |
          cd llama.cpp/build
          DIFF_TEXT="Reviewing the following files: $FILES"
          $EXECUTABLE -m ../../models/tinyllama.gguf -p "$DIFF_TEXT" > ../../review.txt

      # 9. Post AI review as a comment to the pull request
      - name: Post AI Review as Comment
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # GitHub Action에서 기본 제공하는 토큰
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # GitHub CLI에 사용할 토큰
        run: |
          COMMENT=$(cat review.txt)
          gh pr comment ${{ github.event.pull_request.number }} --body "$COMMENT"
